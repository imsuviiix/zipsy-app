import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import io
import zipfile
import os
# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì§‘íšŒì‹œìœ„ ì •ë³´ ì¶”ì¶œê¸°", page_icon="ğŸ“‹")

st.title("ğŸ“‹ ì§‘íšŒì‹œìœ„ ì •ë³´ ì¶”ì¶œê¸°")
st.write("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì§‘íšŒ ë° ì‹œìœ„ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¶„ë¥˜í•©ë‹ˆë‹¤.")

# API í‚¤ ì„¤ì • (Streamlit Secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°)
try:
    API_KEY = st.secrets["API_KEY"]
except:
    API_KEY = os.getenv("UPSTAGE_API_KEY")
    # st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
    # st.stop()

def process_pdf(pdf_file):
    """PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ HTMLë¡œ ë³€í™˜"""
    url = "https://api.upstage.ai/v1/document-digitization"
    headers = {"Authorization": f"Bearer {API_KEY}"}
    files = {"document": pdf_file}
    data = {
        "model": "document-parse-250508",
        "ocr": "force",
        "coordinates": True,
        "output_formats": '["html"]',
        "base64_encoding": "['table']"
    }
    
    response = requests.post(url, headers=headers, files=files, data=data)
    return response.json()

def fix_html_structure(html_content):
    """HTML í…Œì´ë¸” êµ¬ì¡° ìˆ˜ì •"""
    soup = BeautifulSoup(html_content, 'html.parser')
    
    tables = soup.find_all('table')
    for table in tables:
        tbody = table.find('tbody')
        if tbody:
            rows = tbody.find_all('tr')
            for row in rows:
                tds = row.find_all('td')
                current_td_count = len(tds)
                
                # 8ê°œë³´ë‹¤ ì ìœ¼ë©´ ì•ìª½ì— ë¹ˆ ì…€ ì¶”ê°€
                if current_td_count < 8:
                    missing_count = 8 - current_td_count
                    for _ in range(missing_count):
                        new_td = soup.new_tag('td')
                        new_td.string = ''
                        row.insert(0, new_td)
                
                # 8ê°œë³´ë‹¤ ë§ìœ¼ë©´ ì´ˆê³¼í•˜ëŠ” ì…€ ì œê±°
                elif current_td_count > 8:
                    excess_tds = row.find_all('td')[8:]
                    for td in excess_tds:
                        td.decompose()
    
    return str(soup)

def mask_personal_info(text):
    """ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹: 00ì„ â—¯â—¯ë¡œ ë³€ê²½"""
    # í•œê¸€ ì„±ì”¨ + 00 íŒ¨í„´ì„ ì°¾ì•„ì„œ â—¯â—¯ë¡œ ë³€ê²½
    # ì˜ˆ: ê¹€00, ì´00, ë°•00 ë“±
    masked_text = re.sub(r'([ê°€-í£])00', r'\1â—¯â—¯', text)
    
    # ê°œì¸(ì„±00) íŒ¨í„´ë„ ì²˜ë¦¬
    masked_text = re.sub(r'ê°œì¸\(([ê°€-í£])00\)', r'ê°œì¸(\1â—¯â—¯)', masked_text)
    
    return masked_text

def parse_data(html_content):
    """HTMLì—ì„œ ë°ì´í„° ì¶”ì¶œ ë° íŒŒì‹±"""
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # í…Œì´ë¸”ì—ì„œ í–‰ ì¶”ì¶œ
    tables = soup.find_all("table")
    all_rows = []
    
    for table in tables:
        tbody = table.find("tbody")
        if not tbody:
            continue
        
        rows = tbody.find_all("tr")
        for row in rows:
            cols = [col.get_text(strip=True) for col in row.find_all("td")]
            if len(cols) >= 6:
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼(ë²ˆí˜¸) ì œê±°í•˜ê³  ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©
                if cols[0].isdigit() or cols[0].startswith('-'):
                    cols = cols[1:]  # ë²ˆí˜¸ ì»¬ëŸ¼ ì œê±°
                all_rows.append(cols)
    
    # ë°ì´í„° ì •ë¦¬
    cleaned_rows = []
    prev_row = [""] * 8
    
    for row in all_rows:
        current_row = row + [""] * (8 - len(row)) if len(row) < 8 else row[:8]
        
        for i in range(8):
            if current_row[i] and current_row[i].strip():
                prev_row[i] = current_row[i]
            else:
                current_row[i] = prev_row[i]
        
        if len(current_row) >= 8 and current_row[2] and current_row[3]:
            cleaned_rows.append(current_row)
    
    # í¬ë§· ë³€í™˜
    formatted_entries = []
    for row in cleaned_rows:
        # ì»¬ëŸ¼ ìˆ˜ì— ë”°ë¼ ë‹¤ë¥¸ ë§¤í•‘ ì ìš©
        if len(row) == 5:
            # 5ê°œ ì»¬ëŸ¼: [ì£¼ìµœì, ì‹œê°„ì¥ì†Œ, ì¸ì›, í–‰ì‚¬ìœ í˜•, ê´€í• ]
            organizer = row[0] if row[0] else "ì£¼ìµœìë¶ˆëª…"
            time_loc = row[1] if row[1] else "ì‹œê°„ì¥ì†Œë¶ˆëª…"
            people = row[2] if row[2] else "ì¸ì›ë¶ˆëª…"
            event_type = row[3] if row[3] else "í–‰ì‚¬ìœ í˜•ë¶ˆëª…"
            region_text = row[4] if row[4] else "ê´€í• ë¶ˆëª…"
            event = organizer  # ì£¼ìµœìë¥¼ í–‰ì‚¬ëª…ìœ¼ë¡œ ì‚¬ìš©
        elif len(row) == 6:
            # 6ê°œ ì»¬ëŸ¼: [ì£¼ìµœì, í–‰ì‚¬ëª…, ì‹œê°„ì¥ì†Œ, ì¸ì›, í–‰ì‚¬ìœ í˜•, ê´€í• ]
            organizer = row[0] if row[0] else "ì£¼ìµœìë¶ˆëª…"
            event = row[1].replace(" ", "") if row[1] else "í–‰ì‚¬ëª…ë¶ˆëª…"
            time_loc = row[2] if row[2] else "ì‹œê°„ì¥ì†Œë¶ˆëª…"
            people = row[3] if row[3] else "ì¸ì›ë¶ˆëª…"
            event_type = row[4] if row[4] else "í–‰ì‚¬ìœ í˜•ë¶ˆëª…"
            region_text = row[5] if row[5] else "ê´€í• ë¶ˆëª…"
        elif len(row) == 7:
            # 7ê°œ ì»¬ëŸ¼: [ì£¼ìµœì, í–‰ì‚¬ëª…, ì‹œê°„ì¥ì†Œ, ì¸ì›, í–‰ì‚¬ìœ í˜•, ê´€í• , ì¶”ê°€ì •ë³´]
            organizer = row[0] if row[0] else "ì£¼ìµœìë¶ˆëª…"
            event = row[1].replace(" ", "") if row[1] else "í–‰ì‚¬ëª…ë¶ˆëª…"
            time_loc = row[2] if row[2] else "ì‹œê°„ì¥ì†Œë¶ˆëª…"
            people = row[3] if row[3] else "ì¸ì›ë¶ˆëª…"
            event_type = row[4] if row[4] else "í–‰ì‚¬ìœ í˜•ë¶ˆëª…"
            region_text = row[5] if row[5] else "ê´€í• ë¶ˆëª…"
        else:
            # 8ê°œ ì»¬ëŸ¼: [ì£¼ìµœì, í–‰ì‚¬ëª…, ì‹œê°„ì¥ì†Œ, ì¸ì›, í–‰ì‚¬ìœ í˜•, ê´€í• , ì¶”ê°€ì •ë³´, ì¶”ê°€ì •ë³´]
            organizer = row[2] if row[2] else "ì£¼ìµœìë¶ˆëª…"
            event = row[3].replace(" ", "") if row[3] else "í–‰ì‚¬ëª…ë¶ˆëª…"
            time_loc = row[4] if row[4] else "ì‹œê°„ì¥ì†Œë¶ˆëª…"
            people = row[5] if row[5] else "ì¸ì›ë¶ˆëª…"
            event_type = row[6] if row[6] else "í–‰ì‚¬ìœ í˜•ë¶ˆëª…"
            region_text = row[7] if row[7] else "ê´€í• ë¶ˆëª…"
        
        # ì£¼ìµœìì—ë§Œ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ ì ìš©
        organizer = mask_personal_info(organizer)
        
        # ì‹œê°„ê³¼ ì¥ì†Œ ë¶„ë¦¬
        if "~" in time_loc:
            # ë‹¤ì–‘í•œ ì‹œê°„ íŒ¨í„´ ë§¤ì¹­
            time_patterns = [
                r'(\d{1,2}:\d{2}~\d{1,2}:\d{2})',  # 17:00~22:00
                r'(\d{1,2}:\d{2}âˆ¼\d{1,2}:\d{2})',  # 17:00âˆ¼22:00
                r'(\d{1,2}:\d{2}~æœªå®š)',  # 18:30~æœªå®š
                r'(\d{1,2}:\d{2}âˆ¼æœªå®š)',  # 18:30âˆ¼æœªå®š
                r'(\d{1,2}:\d{2}~\s*ç¿Œ\)\d{1,2}:\d{2})',  # 23:00~ ç¿Œ)03:00
                r'(\d{1,2}:\d{2}âˆ¼\s*ç¿Œ\)\d{1,2}:\d{2})',  # 23:00âˆ¼ ç¿Œ)03:00
                r'(\d{1,2}:\d{2}~\d{1,2}:\d{2}~\d{1,2}:\d{2})',  # ë³µí•© ì‹œê°„
                r'(\d{1,2}:\d{2}âˆ¼\d{1,2}:\d{2}âˆ¼\d{1,2}:\d{2})',  # ë³µí•© ì‹œê°„
                r'(\d{1,2}:\d{2}~\d{1,2}:\d{2}\s+\d{1,2}:\d{2}~\d{1,2}:\d{2})',  # ì—¬ëŸ¬ ì‹œê°„ëŒ€
                r'(\d{1,2}:\d{2}âˆ¼\d{1,2}:\d{2}\s+\d{1,2}:\d{2}âˆ¼\d{1,2}:\d{2})',  # ì—¬ëŸ¬ ì‹œê°„ëŒ€
            ]
            
            time_found = False
            for pattern in time_patterns:
                time_match = re.search(pattern, time_loc)
                if time_match:
                    time = time_match.group(1)
                    location = time_loc.replace(time, "").strip()
                    location = re.sub(r'<[^>]*>', '', location).strip()
                    time_found = True
                    break
            
            if not time_found:
                time = "ì‹œê°„ì •ë³´ì—†ìŒ"
                location = re.sub(r'<[^>]*>', '', time_loc).strip()
        else:
            time = "ì‹œê°„ì •ë³´ì—†ìŒ"
            location = re.sub(r'<[^>]*>', '', time_loc).strip()
        
        # ê´€í• ì„œ ì¶”ì¶œ
        region_match = re.search(r'([ê°€-í£\s]+)\s*<[^>]*>', region_text)
        if region_match:
            region = region_match.group(1).strip().replace(" ", "")
        else:
            region_parts = region_text.split()
            region = region_parts[-1].replace(" ", "") if region_parts else "ê´€í• ë¶ˆëª…"
        
        formatted = f"-{organizer}/{event}/{time}/{location}/{people}/ì§‘íšŒ/{region}"
        formatted_entries.append(formatted)
    
    return formatted_entries

def classify_entries(entries):
    """ê´€í• ë³„ë¡œ ë¶„ë¥˜"""
    mayoung_regions = ["ë§ˆí¬", "ì„œëŒ€ë¬¸", "ì€í‰", "ì„œë¶€", "ì˜ë“±í¬", "êµ¬ë¡œ", "ê°•ì„œ", "ì–‘ì²œ", "ê´€ì•…", "ë°©ë°°", "ê¸ˆì²œ", "ë™ì‘"]
    ganggwang_regions = ["ê°•ë‚¨", "ì„œì´ˆ", "ìˆ˜ì„œ", "ì†¡íŒŒ", "ì„±ë™", "ê°•ë™", "ê´‘ì§„"]
    
    mayoung_entries = []
    ganggwang_entries = []
    jungjong_entries = []
    
    for entry in entries:
        region = entry.split("/")[-1]
        
        if any(r in region for r in mayoung_regions):
            mayoung_entries.append(entry)
        elif any(r in region for r in ganggwang_regions):
            ganggwang_entries.append(entry)
        else:
            jungjong_entries.append(entry)
    
    return mayoung_entries, ganggwang_entries, jungjong_entries

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=['pdf'])

if uploaded_file is not None:
    with st.spinner('PDF íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...'):
        try:
            # PDF ì²˜ë¦¬
            response_data = process_pdf(uploaded_file)
            
            # HTML ìˆ˜ì§‘ ë° êµ¬ì¡° ìˆ˜ì •
            html_parts = []
            if "elements" in response_data:
                for element in response_data["elements"]:
                    if "content" in element and "html" in element["content"]:
                        html_content = element["content"]["html"]
                        if html_content and html_content.strip():
                            fixed_html = fix_html_structure(html_content)
                            html_parts.append(fixed_html)
            
            # ë°ì´í„° íŒŒì‹±
            all_html = ''.join(html_parts)
            formatted_entries = parse_data(all_html)
            
            # ê´€í• ë³„ ë¶„ë¥˜
            mayoung_entries, ganggwang_entries, jungjong_entries = classify_entries(formatted_entries)
            
            st.success(f'ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(formatted_entries)}ê±´ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.')
            
            # ê²°ê³¼ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.subheader(f"ğŸ”µ ë§ˆì˜ê´€ ({len(mayoung_entries)}ê±´)")
                for entry in mayoung_entries:
                    st.text(entry)
            
            with col2:
                st.subheader(f"ğŸŸ¢ ê°•ê´‘ ({len(ganggwang_entries)}ê±´)")
                for entry in ganggwang_entries:
                    st.text(entry)
            
            with col3:
                st.subheader(f"ğŸŸ¡ ì¤‘ì¢… ({len(jungjong_entries)}ê±´)")
                for entry in jungjong_entries:
                    st.text(entry)
            
            # ë‹¤ìš´ë¡œë“œ íŒŒì¼ ìƒì„±
            def create_download_files():
                files = {}
                
                # ì „ì²´
                files['ì§‘íšŒì‹œìœ„ì •ë³´_ì „ì²´.txt'] = '\n'.join(formatted_entries)
                
                # ë§ˆì˜ê´€
                mayoung_content = f"=== ë§ˆì˜ê´€ ===\nì´ {len(mayoung_entries)}ê±´\n\n" + '\n'.join(mayoung_entries)
                files['ì§‘íšŒì‹œìœ„ì •ë³´_ë§ˆì˜ê´€.txt'] = mayoung_content
                
                # ê°•ê´‘
                ganggwang_content = f"=== ê°•ê´‘ ===\nì´ {len(ganggwang_entries)}ê±´\n\n" + '\n'.join(ganggwang_entries)
                files['ì§‘íšŒì‹œìœ„ì •ë³´_ê°•ê´‘.txt'] = ganggwang_content
                
                # ì¤‘ì¢…
                jungjong_content = f"=== ì¤‘ì¢… ===\nì´ {len(jungjong_entries)}ê±´\n\n" + '\n'.join(jungjong_entries)
                files['ì§‘íšŒì‹œìœ„ì •ë³´_ì¤‘ì¢….txt'] = jungjong_content
                
                return files
            
            files = create_download_files()
            
            # ZIP íŒŒì¼ ìƒì„±
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                for filename, content in files.items():
                    zip_file.writestr(filename, content.encode('utf-8'))
            
            zip_buffer.seek(0)
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            st.download_button(
                label="ğŸ“ ëª¨ë“  íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ZIP)",
                data=zip_buffer.getvalue(),
                file_name="ì§‘íšŒì‹œìœ„ì •ë³´.zip",
                mime="application/zip"
            )
            
        except Exception as e:
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ì‚¬ìš©ë²• ì„¤ëª…
with st.expander("ì‚¬ìš©ë²•"):
    st.write("""
    1. PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
    2. ìë™ìœ¼ë¡œ ì§‘íšŒ/ì‹œìœ„ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤
    3. ê´€í• ë³„ë¡œ ë¶„ë¥˜ëœ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”
    4. ZIP íŒŒì¼ë¡œ ëª¨ë“  ê²°ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    
    **ë¶„ë¥˜ ê¸°ì¤€:**
    - ë§ˆì˜ê´€: ë§ˆí¬, ì„œëŒ€ë¬¸, ì€í‰, ì„œë¶€, ì˜ë“±í¬, êµ¬ë¡œ, ê°•ì„œ, ì–‘ì²œ, ê´€ì•…, ë°©ë°°, ê¸ˆì²œ, ë™ì‘
    - ê°•ê´‘: ê°•ë‚¨, ì„œì´ˆ, ìˆ˜ì„œ, ì†¡íŒŒ, ì„±ë™, ê°•ë™, ê´‘ì§„
    - ì¤‘ì¢…: ë‚˜ë¨¸ì§€ ì§€ì—­
    
    **ê°œì¸ì •ë³´ ë³´í˜¸:**
    - ê°œì¸ëª…ì˜ '00' í‘œê¸°ëŠ” ìë™ìœ¼ë¡œ 'â—¯â—¯'ë¡œ ë§ˆìŠ¤í‚¹ë©ë‹ˆë‹¤
    """)